
### Daily Research: 2026-02-02
### Query: "deep+computer+vision"
### Found *5* relevant papers.
#===================================================#



Paper: Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models

Authors: Yi Zhang, Chun-Wun Cheng, Angelica I. Aviles-Rivero et al.

Categories: cs.CV, cs.LG

Published: 2026-01-30 18:21 UTC

Source: Arxiv

Summary: Vision-language models suffer performance degradation under domain shift, limiting real-world applicability. Existing test-time adaptation methods are computationally intensive, rely on back-propagation, and often focus on single modalities. To address these issues, we propose Training-free Test-Time Adaptation with Brownian Distance Covariance (TaTa). TaTa leverages Brownian Distance Covariance-a... 

#===================================================#

Why it matters: Paper 2 addresses critical test-time adaptation for Vision Language Models (VLMs), a high-impact area in modern computer vision where real-time performance and robustness are essential. 

Relevance Score: 0.69/1.00

[Read more](http://arxiv.org/abs/2601.23253v1)

#===================================================#


Paper: Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging

Authors: Shuhong Liu, Xining Ge, Ziying Gu et al.

Categories: astro-ph.IM, cs.CV, cs.LG

Published: 2026-01-30 18:47 UTC

Source: Arxiv

Summary: Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically interpretable and reproducible models in scientific workflows. We propose a ... 

#===================================================#

Why it matters: Paper 3 focuses on astronomical image denoising, a specialized but valid computer vision task that requires advanced signal processing techniques relevant to image analysis. 

Relevance Score: 0.69/1.00

[Read more](http://arxiv.org/abs/2601.23276v1)

#===================================================#


Paper: Structured Over Scale: Learning Spatial Reasoning from Educational Video

Authors: Bishoy Galoaa, Xiangyu Bai, Sarah Ostadabbas

Categories: cs.CV

Published: 2026-01-30 18:20 UTC

Source: Arxiv

Summary: Vision-language models (VLMs) demonstrate impressive performance on standard video understanding benchmarks yet fail systematically on simple reasoning tasks that preschool children can solve, including counting, spatial reasoning, and compositional understanding. We hypothesize that the pedagogically-structured content of educational videos provides an ideal training signal for improving these ca... 

#===================================================#

Why it matters: Paper 4 improves spatial reasoning in video understanding, a core capability for applications like autonomous systems and robotics. 

Relevance Score: 0.69/1.00

[Read more](http://arxiv.org/abs/2601.23251v1)

#===================================================#


Paper: User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments

Authors: Junfeng Lin, Yanming Xiu, Maria Gorlatova

Categories: cs.CV

Published: 2026-01-30 18:55 UTC

Source: Arxiv

Summary: Open-set object detection (OSOD) localizes objects while identifying and rejecting unknown classes at inference. While recent OSOD models perform well on benchmarks, their behavior under realistic user prompting remains underexplored. In interactive XR settings, user-generated prompts are often ambiguous, underspecified, or overly detailed. To study prompt-conditioned robustness, we evaluate two O... 

#===================================================#

Why it matters: Paper 5 provides practical solutions for object detection in real-world XR environments, addressing challenges in dynamic and uncontrolled settings. 

Relevance Score: 0.68/1.00

[Read more](http://arxiv.org/abs/2601.23281v1)

#===================================================#


Paper: VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation

Authors: Hongyang Du, Junjie Ye, Xiaoyan Cong et al.

Categories: cs.CV, cs.AI, cs.LG

Published: 2026-01-30 18:59 UTC

Source: Arxiv

Summary: While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference A... 

#===================================================#

Why it matters: Paper 9 advances 3D-consistent video generation, a key frontier in computer vision with applications in virtual reality, robotics, and augmented reality.

Relevance Score: 0.63/1.00

[Read more](http://arxiv.org/abs/2601.23286v1)

#===================================================#

Papers similar in chroma_db to 'deep+computer+vision':

1) HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval.
Similarity: 0.6163

2) Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models.
Similarity: 0.5822

3) Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models.
Similarity: 0.5822

4) Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models.
Similarity: 0.5822

#===================================================#

Additional takeaways:
Trending categories: cs.AI, astro-ph.IM, cs.LG, cs.CV
Sources count:arxiv: 5 papers

Most active fields: cs.CV"

#===================================================#          

This post is AI-generated. 2026-02-02 16:30 UTC*
